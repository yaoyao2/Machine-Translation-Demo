{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "X, Y, en_word2idx, en_idx2word, en_vocab, de_word2idx, de_idx2word, de_vocab = pickle.load(open(\"data.pkl\", 'rb'), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence in English - encoded: [108, 5, 867, 93, 38, 25, 2583]\n",
      "Sentence in German - encoded: [166, 262, 8, 474, 268, 324, 67, 15, 130]\n",
      "Decoded:\n",
      "------------------------\n",
      "They walk in here and \n",
      "\n",
      "Die kommen hier herein und "
     ]
    }
   ],
   "source": [
    "# inspect data\n",
    "print('Sentence in English - encoded:', X[0])\n",
    "print('Sentence in German - encoded:', Y[0])\n",
    "print('Decoded:\\n------------------------')\n",
    "\n",
    "for i in range(len(X[1])):\n",
    "    print(en_idx2word[X[1][i]],end=' ')\n",
    "    \n",
    "print('\\n')\n",
    "\n",
    "for i in range(len(Y[1])):\n",
    "    print(de_idx2word[Y[1][i]],end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing\n",
    "\n",
    "# data padding\n",
    "def data_padding(x, y, length = 15):\n",
    "    for i in range(len(x)):\n",
    "        x[i] = x[i] + (length - len(x[i])) * [en_word2idx['<pad>']]\n",
    "        y[i] = [de_word2idx['<go>']] + y[i] + [de_word2idx['<eos>']] + (length-len(y[i])) * [de_word2idx['<pad>']]\n",
    "\n",
    "data_padding(X, Y)\n",
    "\n",
    "# data splitting\n",
    "X_train,  X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1)\n",
    "\n",
    "del X\n",
    "del Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model\n",
    "\n",
    "input_seq_len = 15\n",
    "output_seq_len = 17\n",
    "en_vocab_size = len(en_vocab) + 2 # + <pad>, <ukn>\n",
    "de_vocab_size = len(de_vocab) + 4 # + <pad>, <ukn>, <eos>, <go>\n",
    "\n",
    "# placeholders\n",
    "encoder_inputs = [tf.placeholder(dtype = tf.int32, shape = [None], name = 'encoder{}'.format(i)) for i in range(input_seq_len)]\n",
    "decoder_inputs = [tf.placeholder(dtype = tf.int32, shape = [None], name = 'decoder{}'.format(i)) for i in range(output_seq_len)]\n",
    "\n",
    "targets = [decoder_inputs[i+1] for i in range(output_seq_len-1)]\n",
    "# add one more target\n",
    "targets.append(tf.placeholder(dtype = tf.int32, shape = [None], name = 'last_target'))\n",
    "target_weights = [tf.placeholder(dtype = tf.float32, shape = [None], name = 'target_w{}'.format(i)) for i in range(output_seq_len)]\n",
    "\n",
    "# output projection\n",
    "size = 512\n",
    "w_t = tf.get_variable('proj_w', [de_vocab_size, size], tf.float32)\n",
    "b = tf.get_variable('proj_b', [de_vocab_size], tf.float32)\n",
    "w = tf.transpose(w_t)\n",
    "output_projection = (w, b)\n",
    "\n",
    "outputs, states = tf.contrib.legacy_seq2seq.embedding_attention_seq2seq(\n",
    "                                            encoder_inputs,\n",
    "                                            decoder_inputs,\n",
    "                                            tf.contrib.rnn.BasicLSTMCell(size),\n",
    "                                            num_encoder_symbols = en_vocab_size,\n",
    "                                            num_decoder_symbols = de_vocab_size,\n",
    "                                            embedding_size = 100,\n",
    "                                            feed_previous = False,\n",
    "                                            output_projection = output_projection,\n",
    "                                            dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\ProgramData\\Anaconda36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:1344: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define our loss function\n",
    "\n",
    "# sampled softmax loss - returns: A batch_size 1-D tensor of per-example sampled softmax losses\n",
    "def sampled_loss(labels, logits):\n",
    "    return tf.nn.sampled_softmax_loss(\n",
    "                        weights = w_t,\n",
    "                        biases = b,\n",
    "                        labels = tf.reshape(labels, [-1, 1]),\n",
    "                        inputs = logits,\n",
    "                        num_sampled = 512,\n",
    "                        num_classes = de_vocab_size)\n",
    "\n",
    "# Weighted cross-entropy loss for a sequence of logits\n",
    "loss = tf.contrib.legacy_seq2seq.sequence_loss(outputs, targets, target_weights, softmax_loss_function = sampled_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define some helper functions\n",
    "\n",
    "# simple softmax function\n",
    "def softmax(x):\n",
    "    n = np.max(x)\n",
    "    e_x = np.exp(x - n)\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "# feed data into placeholders\n",
    "def feed_dict(x, y, batch_size = 64):\n",
    "    feed = {}\n",
    "    \n",
    "    idxes = np.random.choice(len(x), size = batch_size, replace = False)\n",
    "    \n",
    "    for i in range(input_seq_len):\n",
    "        feed[encoder_inputs[i].name] = np.array([x[j][i] for j in idxes], dtype = np.int32)\n",
    "        \n",
    "    for i in range(output_seq_len):\n",
    "        feed[decoder_inputs[i].name] = np.array([y[j][i] for j in idxes], dtype = np.int32)\n",
    "        \n",
    "    feed[targets[len(targets)-1].name] = np.full(shape = [batch_size], fill_value = de_word2idx['<pad>'], dtype = np.int32)\n",
    "    \n",
    "    for i in range(output_seq_len-1):\n",
    "        batch_weights = np.ones(batch_size, dtype = np.float32)\n",
    "        target = feed[decoder_inputs[i+1].name]\n",
    "        for j in range(batch_size):\n",
    "            if target[j] == de_word2idx['<pad>']:\n",
    "                batch_weights[j] = 0.0\n",
    "        feed[target_weights[i].name] = batch_weights\n",
    "        \n",
    "    feed[target_weights[output_seq_len-1].name] = np.zeros(batch_size, dtype = np.float32)\n",
    "    \n",
    "    return feed\n",
    "\n",
    "# decode output sequence\n",
    "def decode_output(output_seq):\n",
    "    words = []\n",
    "    for i in range(output_seq_len):\n",
    "        smax = softmax(output_seq[i])\n",
    "        idx = np.argmax(smax)\n",
    "        words.append(de_idx2word[idx])\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ops and hyperparameters\n",
    "learning_rate = 5e-3\n",
    "batch_size = 64\n",
    "steps = 10\n",
    "\n",
    "# ops for projecting outputs\n",
    "outputs_proj = [tf.matmul(outputs[i], output_projection[0]) + output_projection[1] for i in range(output_seq_len)]\n",
    "\n",
    "# training op\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# init op\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# forward step\n",
    "def forward_step(sess, feed):\n",
    "    output_sequences = sess.run(outputs_proj, feed_dict = feed)\n",
    "    return output_sequences\n",
    "\n",
    "# training step\n",
    "def backward_step(sess, feed):\n",
    "    sess.run(optimizer, feed_dict = feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------TRAINING------------------\n",
      "step: 0, loss: 8.950057983398438\n",
      "step: 4, loss: 9.209945678710938\n",
      "step: 9, loss: 9.043428421020508\n",
      "Training time for 10 steps: 15.001590728759766s\n"
     ]
    }
   ],
   "source": [
    "# let's train the model\n",
    "\n",
    "# we will use this list to plot losses through steps\n",
    "losses = []\n",
    "\n",
    "# save a checkpoint so we can restore the model later \n",
    "saver = tf.train.Saver()\n",
    "\n",
    "print('------------------TRAINING------------------')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    t = time.time()\n",
    "    for step in range(steps):\n",
    "        feed = feed_dict(X_train, Y_train)\n",
    "            \n",
    "        backward_step(sess, feed)\n",
    "        \n",
    "        if step % 5 == 4 or step == 0:\n",
    "            loss_value = sess.run(loss, feed_dict = feed)\n",
    "            print('step: {}, loss: {}'.format(step, loss_value))\n",
    "            losses.append(loss_value)\n",
    "        \n",
    "        if step % 20 == 19:\n",
    "            saver.save(sess, 'checkpoints/', global_step=step)\n",
    "            print('Checkpoint is saved')\n",
    "            \n",
    "    print('Training time for {} steps: {}s'.format(steps, time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot losses\n",
    "\n",
    "with plt.style.context('fivethirtyeight'):\n",
    "    plt.plot(losses, linewidth = 1)\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Losses')\n",
    "    plt.ylim((0, 12))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints\\-999\n",
      "1.\n",
      "--------------------------------\n",
      "What' s your name\n",
      "Wie ist dein Name \n",
      "--------------------------------\n",
      "2.\n",
      "--------------------------------\n",
      "My name is\n",
      "Meine Name ist \n",
      "--------------------------------\n",
      "3.\n",
      "--------------------------------\n",
      "What are you doing\n",
      "Was machst du da \n",
      "--------------------------------\n",
      "4.\n",
      "--------------------------------\n",
      "I am reading a book\n",
      "Ich habe mir eine Buch \n",
      "--------------------------------\n",
      "5.\n",
      "--------------------------------\n",
      "How are you\n",
      "Wie geht' du \n",
      "--------------------------------\n",
      "6.\n",
      "--------------------------------\n",
      "I am good\n",
      "Ich bin gut \n",
      "--------------------------------\n",
      "7.\n",
      "--------------------------------\n",
      "Do you speak English\n",
      "Hast du mal mal \n",
      "--------------------------------\n",
      "8.\n",
      "--------------------------------\n",
      "What time is it\n",
      "Wie ist es ist los \n",
      "--------------------------------\n",
      "9.\n",
      "--------------------------------\n",
      "Hi\n",
      "Hi \n",
      "--------------------------------\n",
      "10.\n",
      "--------------------------------\n",
      "Goodbye\n",
      "Wiedersehen \n",
      "--------------------------------\n",
      "11.\n",
      "--------------------------------\n",
      "Yes\n",
      "Ja \n",
      "--------------------------------\n",
      "12.\n",
      "--------------------------------\n",
      "No\n",
      "Nein \n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "# let's test the model\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    \n",
    "    # placeholders\n",
    "    encoder_inputs = [tf.placeholder(dtype = tf.int32, shape = [None], name = 'encoder{}'.format(i)) for i in range(input_seq_len)]\n",
    "    decoder_inputs = [tf.placeholder(dtype = tf.int32, shape = [None], name = 'decoder{}'.format(i)) for i in range(output_seq_len)]\n",
    "\n",
    "    # output projection\n",
    "    size = 512\n",
    "    w_t = tf.get_variable('proj_w', [de_vocab_size, size], tf.float32)\n",
    "    b = tf.get_variable('proj_b', [de_vocab_size], tf.float32)\n",
    "    w = tf.transpose(w_t)\n",
    "    output_projection = (w, b)\n",
    "    \n",
    "    # change the model so that output at time t can be fed as input at time t+1\n",
    "    outputs, states = tf.contrib.legacy_seq2seq.embedding_attention_seq2seq(\n",
    "                                                encoder_inputs,\n",
    "                                                decoder_inputs,\n",
    "                                                tf.contrib.rnn.BasicLSTMCell(size),\n",
    "                                                num_encoder_symbols = en_vocab_size,\n",
    "                                                num_decoder_symbols = de_vocab_size,\n",
    "                                                embedding_size = 100,\n",
    "                                                feed_previous = True, # <-----this is changed----->\n",
    "                                                output_projection = output_projection,\n",
    "                                                dtype = tf.float32)\n",
    "    \n",
    "    # ops for projecting outputs\n",
    "    outputs_proj = [tf.matmul(outputs[i], output_projection[0]) + output_projection[1] for i in range(output_seq_len)]\n",
    "\n",
    "    # let's translate these sentences     \n",
    "    en_sentences = [\"What' s your name\", 'My name is', 'What are you doing', 'I am reading a book',\\\n",
    "                    'How are you', 'I am good', 'Do you speak English', 'What time is it', 'Hi', 'Goodbye', 'Yes', 'No']\n",
    "    en_sentences_encoded = [[en_word2idx.get(word, 0) for word in en_sentence.split()] for en_sentence in en_sentences]\n",
    "    \n",
    "    # padding to fit encoder input\n",
    "    for i in range(len(en_sentences_encoded)):\n",
    "        en_sentences_encoded[i] += (15 - len(en_sentences_encoded[i])) * [en_word2idx['<pad>']]\n",
    "    \n",
    "    # restore all variables - use the last checkpoint saved\n",
    "    saver = tf.train.Saver()\n",
    "    path = tf.train.latest_checkpoint('checkpoints')\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        # restore\n",
    "        saver.restore(sess, path)\n",
    "        \n",
    "        # feed data into placeholders\n",
    "        feed = {}\n",
    "        for i in range(input_seq_len):\n",
    "            feed[encoder_inputs[i].name] = np.array([en_sentences_encoded[j][i] for j in range(len(en_sentences_encoded))], dtype = np.int32)\n",
    "            \n",
    "        feed[decoder_inputs[0].name] = np.array([de_word2idx['<go>']] * len(en_sentences_encoded), dtype = np.int32)\n",
    "        \n",
    "        # translate\n",
    "        output_sequences = sess.run(outputs_proj, feed_dict = feed)\n",
    "        \n",
    "        # decode seq.\n",
    "        for i in range(len(en_sentences_encoded)):\n",
    "            print('{}.\\n--------------------------------'.format(i+1))\n",
    "            ouput_seq = [output_sequences[j][i] for j in range(output_seq_len)]\n",
    "            #decode output sequence\n",
    "            words = decode_output(ouput_seq)\n",
    "        \n",
    "            print(en_sentences[i])\n",
    "            for i in range(len(words)):\n",
    "                if words[i] not in ['<eos>', '<pad>', '<go>']:\n",
    "                    print(words[i],end=' ')\n",
    "            \n",
    "            print('\\n--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
